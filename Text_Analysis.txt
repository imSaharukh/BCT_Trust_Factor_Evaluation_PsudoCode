Take input_raw_text as input

## This is a pseudocode for our framework
Input text in a container variable named user_input
While(user_input != NULL)
    if there exist \n 
        split the user_input into a list named input_para
    else read forward

#Let, a list of punctuation be:
punctuations = [".", ";", "?", "!"]
## Segmentation: Break the document down into sentences with punctuations
While(user_para != NULL)
    if there exists any punctuation
        split input_para into lines
        append lines into a list named input_lines
    else read input_para further
Let, line_index=0

## Tokenizing: break down the words of sentences individually and store the words where each word is a token
for line_index< len(input_lines)
    if there exists any blank space
        split the lines into words
        append each word into token_list
    else line_index+1

## Stop words:Remove non-meaningful/ no-essential words(‘was’, ‘and’, ‘the’) to read the document faster
#Let, a list of non-meaningful words be:
stop_words=["was", "and","the",.....]
Let, token_index=0
for token_index< len(token_list)
    if there exists a stop_word in token_list[token_index]
        delete token
        token_index-1
